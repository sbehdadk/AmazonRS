{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "rs",
   "display_name": "TensorFlow-GPU",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Importing Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "from preprocess_data import dataloader\n",
    "from siamese_train import siamese_network\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import rotate, AffineTransform, warp, rescale\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Lambda, Input, Flatten, Dense, Concatenate, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "source": [
    "## Plot Training Accuracy and Training Loss\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(loss, acc):\n",
    "    \n",
    "    size = len(acc)\n",
    "    x = np.array(range(1,size+1))\n",
    "    xnew = np.linspace(1,size,100)\n",
    "\n",
    "    spl = make_interp_spline(x, acc, k=3) #BSpline object\n",
    "    ynew = spl(xnew)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(acc,color = 'b', alpha=0.4, label = 'Avg Batch Accuracy')\n",
    "    plt.plot(xnew, ynew,color = 'b', alpha=1, label = 'Smooth Average Accuracy')\n",
    "    plt.xlabel('Steps (for every 500)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    spl = make_interp_spline(x, loss, k=3) #BSpline object\n",
    "    ynew = spl(xnew)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(loss,color = 'b', label = 'Avg Batch Loss')\n",
    "    #plt.plot((xnew, ynew),color = 'b', alpha=1)\n",
    "    plt.xlabel('Steps (for every 500)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'val_acc'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c0db09cb35ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# os.path.join(save_path,\"val.pickle\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(os.path.getsize('val_acc'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'val_acc'"
     ]
    }
   ],
   "source": [
    "# os.path.join(save_path,\"val.pickle\")\n",
    "#print(os.path.getsize('val_acc'))\n",
    "with open('val_acc', 'r') as f:\n",
    "    v_acc,train_metrics = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = np.array(train_metrics)\n",
    "plot_metric(train_metrics[:,0],train_metrics[:,1])"
   ]
  },
  {
   "source": [
    "## Plotting Validation Accuracy on 20 - way one shot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_acc  =np.array(v_acc)\n",
    "\n",
    "x = np.array(range(1,len(v_acc)+1))\n",
    "xnew = np.linspace(1,len(v_acc),100)\n",
    "\n",
    "spl = make_interp_spline(x, v_acc[:,0], k=3) #BSpline object\n",
    "ynew1 = spl(xnew)\n",
    "spl = make_interp_spline(x, v_acc[:,1], k=3) #BSpline object\n",
    "ynew2 = spl(xnew)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(v_acc[:,0], color = 'b', alpha=0.4,  label = 'within alphabet pairs')\n",
    "plt.plot(xnew, ynew1, color = 'b', alpha=1, label = 'smoothed within alphabet pairs')\n",
    "plt.plot(v_acc[:,1], color = 'r', alpha=0.4,  label = 'unstructed alphabets pairs')\n",
    "plt.plot(xnew, ynew2, color = 'r', alpha=1, label = 'smoothed unstructed alphabets pairs')\n",
    "plt.xlabel('Steps (for every 500)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('20-way Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_acc[-1]\n"
   ]
  },
  {
   "source": [
    "# Testing N- way one shot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Loading Saved Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = siamese_network()\n",
    "siamese.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 'best_model/best_model.h5'\n",
    "siamese.model.load_weights(best_model)\n",
    "siamese_net = siamese.model\n",
    "print(\"Model loaded from disk\")"
   ]
  },
  {
   "source": [
    "## Evaluation on 10 Alphabets ( Evaluation Set)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wA_file ='wA_eval_10_split_images.pkl'\n",
    "uA_file ='uA_eval_10_split_images.pkl'\n",
    "\n",
    "wA_acc, uA_acc = siamese.test_validation_acc(wA_file, uA_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Within Alphabet pairs Accuracy for 20-way one shot samples : {}%\".format(wA_acc))\n",
    "print(\"Unstructured Alphabet pairs Accuracy for 20-way one shot samples : {}%\".format(uA_acc))"
   ]
  },
  {
   "source": [
    "## Evaluation on 20 Alphabets ( Image Evaluation Folder)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wA_file ='wA_eval_20_split_images.pkl'\n",
    "uA_file ='uA_eval_20_split_images.pkl'\n",
    "\n",
    "wA_acc, uA_acc = siamese.test_validation_acc(wA_file, uA_file)\n",
    "\n",
    "print(\"Within Alphabet pairs Accuracy for 20-way one shot samples : {}%\".format(wA_acc))\n",
    "print(\"Unstructured Alphabet pairs Accuracy for 20-way one shot samples : {}%\".format(uA_acc))"
   ]
  },
  {
   "source": [
    "## N-way one shot Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import dataloader\n",
    "import os \n",
    "\n",
    "folder_path = 'images_evaluation'\n",
    "dir_list = os.listdir(folder_path)\n",
    "dl = dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour_correct(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    X_left, X_right = pairs\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sqrt(abs(np.sum(X_left[i]**2 - X_right[i]**2)))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_pairs(n_way = 20, wA = True):\n",
    "    if wA:\n",
    "        pairs = dl.wA_test_pairs(folder_path = folder_path, dirs = dir_list, savefilename =None, n_way = n_way)\n",
    "    else:\n",
    "        pairs = dl.uA_test_pairs(folder_path = folder_path, dirs = dir_list, savefilename =None, classes = None, n_way = n_way)\n",
    "    \n",
    "    X,y =pairs\n",
    "    correct_pred = 0\n",
    "    nn_correct = 0\n",
    "    j = 0\n",
    "    for i in range(0,len(X),n_way):\n",
    "        X_left, X_right,_y  = X[i: i+n_way,0],X[i: i+n_way,1], y[i : i+n_way]\n",
    "        X_left, X_right, _y = np.array(X_left), np.array(X_right), np.array(_y)\n",
    "\n",
    "        correct_pred += siamese.test_one_shot(X_left, X_right, _y)\n",
    "        nn_correct += nearest_neighbour_correct((X_left, X_right), _y)\n",
    "\n",
    "    acc =  correct_pred*100/(len(X)/n_way)\n",
    "    nn_acc = nn_correct*100/(len(X)/n_way)\n",
    "    return acc, nn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_accuracy():\n",
    "    within_accuracies = []\n",
    "    unstructred_accuracies = []\n",
    "    #[2, 5, 6, 10, 15, 16, 20]\n",
    "    for i in tqdm(range(2, 21)):\n",
    "        within_accuracies.append(test_data_pairs(n_way = i, wA = True))\n",
    "        unstructred_accuracies.append(test_data_pairs(n_way = i, wA = False)) \n",
    "    return within_accuracies ,unstructred_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_accuracies ,unstructred_accuracies = one_shot_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = np.arange(2, 21, 1)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(ways,np.asarray(within_accuracies)[:,0], color = 'b',  label = 'wA 20-way one shot accuracy')\n",
    "plt.plot(ways,np.asarray(unstructred_accuracies)[:,0], color = 'r', label = 'uA 20-way one shot accuracy')\n",
    "plt.plot(ways,np.asarray(within_accuracies)[:,1], color = 'g',  label = 'wA 20-way nearest neighbour accuracy')\n",
    "plt.plot(ways,np.asarray(unstructred_accuracies)[:,1], color = 'm', label = 'uA 20-way nearest neighbour accuracy')\n",
    "plt.xlabel('Steps (for every 500)')\n",
    "plt.xticks(np.arange(2, 22, step=2))\n",
    "plt.ylabel('N-way Accuracy')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('N-way Accuracies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(within_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unstructred_accuracies)\n"
   ]
  },
  {
   "source": [
    "## Visualizing N-way pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_matrix(X_left, X_right, y):\n",
    "    X_left, X_right, _y = np.array(X_left), np.array(X_right), np.array(y)\n",
    "    pred = siamese_net.predict([X_left, X_right])\n",
    "    index = np.argmax(pred)\n",
    "    \n",
    "    img0 = np.squeeze(X_left[0], axis = 2)\n",
    "    X_p = []\n",
    "    img_matrix = []\n",
    "    \n",
    "    for i in range(len(X_right)):\n",
    "        img1 = np.squeeze(X_right[i], axis = 2)\n",
    "        X_p.append(img1)\n",
    "        if len(X_p) == 5:\n",
    "            X_p =np.vstack(X_p)\n",
    "            img_matrix.append(X_p)\n",
    "            X_p = []\n",
    "            \n",
    "    img_matrix = np.asarray(img_matrix)\n",
    "    img_matrix = np.hstack(img_matrix)\n",
    "    return img0, img_matrix, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_n_way(file, n_way = 20):\n",
    "\n",
    "    with open(file,'rb') as f:\n",
    "        X,y = pkl.load(f)\n",
    "\n",
    "    i = random.randint(0,int(len(X)/n_way))\n",
    "\n",
    "    X_left, X_right,_y  = X[i: i+n_way,0],X[i: i+n_way,1], y[i : i+n_way]\n",
    "    img0, img_matrix, index= generate_img_matrix(X_left, X_right, _y)\n",
    "\n",
    "    f, ax=  plt.subplots(1,3, figsize = (20,20))\n",
    "    f.tight_layout()\n",
    "    ax[0].imshow(img0, cmap = 'gray')\n",
    "    ax[0].set_title('Test Image')\n",
    "    ax[1].imshow(img_matrix, cmap = 'gray')\n",
    "    ax[1].set_title('Support Set')\n",
    "    ax[2].imshow(np.squeeze(X_right[index], axis = 2), cmap = 'gray')\n",
    "    ax[2].set_title('Image with highest similarity in Support Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wA_file ='wA_eval_20_split_images.pkl'\n",
    "uA_file ='uA_eval_20_split_images.pkl'"
   ]
  },
  {
   "source": [
    "## Visualizing Within Alphabet Pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_n_way(wA_file,n_way = 20)\n"
   ]
  },
  {
   "source": [
    "## Visualizing Unstructured Alphabet Pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_n_way(uA_file,n_way = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}