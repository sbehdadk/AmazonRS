{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Activation, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "#from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras import backend as k \n",
    "from tensorflow.python.keras.backend import set_session\n",
    "#from tf.compat.v1.keras.backend import set_session\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "from keras.applications import resnet50, vgg16, vgg19, xception, densenet, inception_v3, mobilenet, nasnet, inception_resnet_v2\n",
    "from tensorflow.compat.v1.keras.applications import MobileNetV2\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "#from keras.applications.xception import preprocess_input\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre_process all Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from random import shuffle\n",
    "dog_path = '/home/sina/Desktop/Dataset/Electronics,Accessories&Supplies,Audio&VideoAccessories,Cables&Interconnects,VideoCables/Audio&VideoAccessories/DVICables/*'\n",
    "cat_path = '/home/sina/Desktop/Dataset/Electronics,Accessories&Supplies,Audio&VideoAccessories,Cables&Interconnects,VideoCables/Audio&VideoAccessories/CompositeVideo/*'\n",
    "addrsd = glob.glob(dog_path)\n",
    "addrsc = glob.glob(cat_path)\n",
    "    \n",
    "labelsd = [1 for addr in addrsd]  # 1 = dog, 0 =  cat\n",
    "labelsc = [0 for addr in addrsc]\n",
    "# loop over the input images\n",
    "datad = []\n",
    "for imagePath in addrsd:\n",
    "# load the image, pre-process it, and store it in the data list\n",
    "    img = cv2.imread(imagePath)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    datad.append(img)\n",
    "datac = []\n",
    "for imagePath in addrsc:\n",
    "# load the image, pre-process it, and store it in the data list\n",
    "    img = cv2.imread(imagePath)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    datac.append(img)\n",
    "# to shuffle data\n",
    "shuffle_data = True\n",
    "if shuffle_data:\n",
    "    d = list(zip(datad, labelsd))\n",
    "    c = list(zip(datac, labelsc))\n",
    "    e = d + c\n",
    "    shuffle(e)\n",
    "    data, labels = zip(*e)\n",
    "del datad\n",
    "del datac\n",
    "del addrsd\n",
    "del addrsc\n",
    "    \n",
    "Y_train = np.array(labels)\n",
    "X_train = np.array(data, dtype=\"int8\")\n",
    "#preprocess for Resnet- 50\n",
    "X_train =  preprocess_input(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the architecture of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two inputs one each - left and right image\n",
    "left_input = Input((224,224,3))\n",
    "right_input = Input((224,224,3))\n",
    "#Import Resnetarchitecture from keras application and initializing each layer with pretrained imagenet weights.\n",
    "\n",
    "#Please note that it’s usually better to intialize the layers with imagenet initializations than random. While training I will be updating the weights for each layer in each epoch. we don’t want to confuse this activity with transfer learning as I am not freezing any layer but initilializing each layer with imagenet weights\n",
    "# Two inputs one each - left and right image\n",
    "left_input = Input((224,224,3))\n",
    "right_input = Input((224,224,3))\n",
    "#Import Resnetarchitecture from keras application and initializing each layer with pretrained imagenet weights.\n",
    "\n",
    "#Please note that it’s usually better to intialize the layers with imagenet initializations than random. While training I will be updating the weights for each layer in each epoch. we don’t want to confuse this activity with transfer learning as I am not freezing any layer but initilializing each layer with imagenet weights\n",
    "\n",
    "convnet = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "# Add the final fully connected layers\n",
    "x = convnet.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "preds = Dense(18, activation='sigmoid')(x) # Apply sigmoid\n",
    "convnet = Model(inputs=convnet.input, outputs=preds)\n",
    "#Applying above model for both the left and right images\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "# Euclidian Distance between the two images or encodings through the Resnet-50 architecture\n",
    "Euc_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "# use and add the distance function\n",
    "Euc_distance = Euc_layer([encoded_l, encoded_r])\n",
    "#identify the prediction\n",
    "prediction = Dense(1,activation='sigmoid')(Euc_distance)\n",
    "#Define the network with the left and right inputs and the ouput prediction\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "#define the optimizer. Here I have used SGD with nesterov momentum\n",
    "\n",
    "optim = optimizers.SGD(lr=0.001, decay=.01, momentum=0.9, nesterov=True)\n",
    "#compile the network using binary cross entropy loss and the above optimizer\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n",
    "convnet = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "# Add the final fully connected layers\n",
    "x = convnet.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "preds = Dense(18, activation='sigmoid')(x) # Apply sigmoid\n",
    "convnet = Model(inputs=convnet.input, outputs=preds)\n",
    "#Applying above model for both the left and right images\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "# Euclidian Distance between the two images or encodings through the Resnet-50 architecture\n",
    "Euc_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "# use and add the distance function\n",
    "Euc_distance = Euc_layer([encoded_l, encoded_r])\n",
    "#identify the prediction\n",
    "prediction = Dense(1,activation='sigmoid')(Euc_distance)\n",
    "#Define the network with the left and right inputs and the ouput prediction\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "#define the optimizer. Here I have used SGD with nesterov momentum\n",
    "\n",
    "optim = optimizers.SGD(lr=0.001, decay=.01, momentum=0.9, nesterov=True)\n",
    "#compile the network using binary cross entropy loss and the above optimizer\n",
    "\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pairs are created with 2 labels as 0 & 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test & train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_list = X_train[:180]\n",
    "label_list = Y_train[:180]\n",
    "left_input = []\n",
    "right_input = []\n",
    "targets = []\n",
    "#Number of pairs per image\n",
    "pairs = 8\n",
    "#create the dataset to train on\n",
    "for i in range(len(label_list)):\n",
    "    for j in range(pairs):\n",
    "# we need to make sure that we are not comparing with the same image\n",
    "        compare_to = i\n",
    "        while compare_to == i: \n",
    "            compare_to = random.randint(0,179)\n",
    "        left_input.append(image_list[i])\n",
    "        right_input.append(image_list[compare_to])\n",
    "        if label_list[i] == label_list[compare_to]:\n",
    "            # if the images are same then label - 1\n",
    "            targets.append(1.)\n",
    "        else:\n",
    "            # if the images are different then label - 0\n",
    "            targets.append(0.)\n",
    "            \n",
    "#remove single-dimensional entries from the shape of the arrays and making them ready to create the train & datasets \n",
    " \n",
    "#the train data - left right images arrays and target label\n",
    "left_input = np.squeeze(np.array(left_input))\n",
    "right_input = np.squeeze(np.array(right_input))\n",
    "targets = np.squeeze(np.array(targets))\n",
    "# Creating test datasets - left, right images and target label\n",
    "dog_image = X_train[4] #dog_image = 1, cat_image = 0\n",
    "test_left = []\n",
    "test_right = []\n",
    "test_targets = []\n",
    "for i in range(len(Y_train)-180):\n",
    "    test_left.append(dog_image)\n",
    "    test_right.append(X_train[i+180])\n",
    "    test_targets.append(Y_train[i+180])\n",
    "test_left = np.squeeze(np.array(test_left))\n",
    "test_right = np.squeeze(np.array(test_right))\n",
    "test_targets = np.squeeze(np.array(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the code using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-72c0d8ea59ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#from keras_input_pipeline import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "#from keras_input_pipeline import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "siamese_net.summary()\n",
    "with tf.device('/gpu:1'):\n",
    "    siamese_net.fit([left_input,right_input], targets,\n",
    "          batch_size=16,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=([test_left,test_right],test_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
